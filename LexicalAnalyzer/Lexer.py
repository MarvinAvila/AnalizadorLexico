import ply.lex as lex

# ------------------------ DefiniciÃ³n de Tokens ------------------------

reserved = {
    "inicio": "INICIO",
    "fin": "FIN",
    "si": "SI",
    "entonces": "ENTONCES",
    "sino": "SINO",
    "fin_si": "FIN_SI",
    "mientras": "MIENTRAS",
    "fin_mientras": "FIN_MIENTRAS",
    "para": "PARA",
    "desde": "DESDE",
    "hasta": "HASTA",
    "con_paso": "CON_PASO",
    "fin_para": "FIN_PARA",
    "repetir": "REPETIR",
    "hasta_que": "HASTA_QUE",
    "mostrar": "MOSTRAR",
    "hacer": "HACER",
    
}

tokens = [
    "LITERAL_ENTERO",
    "LITERAL_DECIMAL",
    "LITERAL_CADENA",
    "LITERAL_BOOLEANO",
    "IDENTIFICADOR",
    "TIPO",
    "ASIGNACION",
    "PUNTO_COMA",
    "PARENTESIS_IZQ",  
    "PARENTESIS_DER",
    "SUMA",
    "RESTA",
    "MULTIPLICACION",
    "DIVISION",
    "AND",
    "OR",
    "NOT",
    "COMA",
    "MAYOR_QUE",       
    "MENOR_QUE",       
    "MAYOR_IGUAL",     
    "MENOR_IGUAL",     
    "IGUAL_IGUAL",     
    "DIFERENTE",       
] + list(reserved.values())


# ðŸ”¹ Tipos de Datos (entero, decimal, cadena, booleano, constante)
def t_TIPO(t):
    r"\b(entero|decimal|cadena|booleano|constante)\b"  # Solo estos tipos de datos
    print(f"ðŸ“Œ Token detectado: {t.type} -> {t.value}")
    return t


# ðŸ”¹ Valores booleanos (verdadero, falso)
def t_LITERAL_BOOLEANO(t):
    r"\b(verdadero|falso)\b"
    t.value = ("BOOLEANO", t.value == "verdadero")  # ðŸ”¥ Convertir a `True/False`
    print(f"ðŸ“Œ Token detectado: {t.type} -> {t.value}")
    return t


def t_IDENTIFICADOR(t):
    r"[a-zA-Z_][a-zA-Z0-9_]*"
    t.type = reserved.get(t.value, "IDENTIFICADOR")  # Verifica si es palabra reservada
    print(f"ðŸ“Œ Token detectado: {t.type} -> {t.value}")
    return t


# ðŸ”¹ Definir `;` como token vÃ¡lido
t_PUNTO_COMA = r";"


# ðŸ”¹ NÃºmeros decimales
def t_LITERAL_DECIMAL(t):
    r"\d+\.\d+"
    t.value = ("DECIMAL", float(t.value))
    print(f"ðŸ“Œ Token detectado: LITERAL_DECIMAL -> {t.value}")
    return t


# ðŸ”¹ NÃºmeros enteros
def t_LITERAL_ENTERO(t):
    r"\d+"
    t.value = ("ENTERO", int(t.value))
    print(f"ðŸ“Œ Token detectado: LITERAL_ENTERO -> {t.value}")
    return t


# ðŸ”¹ Cadenas de texto entre comillas
def t_LITERAL_CADENA(t):
    r'"[^"]*"'  # ðŸ”¥ Coincide con cualquier texto entre comillas dobles
    t.value = ("CADENA", t.value.strip('"'))  # ðŸ”¥ Remueve las comillas al almacenar
    print(f"ðŸ“Œ Token detectado: LITERAL_CADENA -> {t.value}")
    return t


# ðŸ”¹ AsignaciÃ³n "="
t_ASIGNACION = r"="

# Definir los tokens para los parÃ©ntesis
t_PARENTESIS_IZQ = r'\('
t_PARENTESIS_DER = r'\)'

#   Coma
t_COMA = r','

# Definir los tokens para operadores aritmÃ©ticos y lÃ³gicos
t_SUMA = r'\+'
t_RESTA = r'-'
t_MULTIPLICACION = r'\*'
t_DIVISION = r'/'
t_AND = r'AND'
t_OR = r'OR'
t_NOT = r'NOT'

# Definir los tokens para operadores de comparaciÃ³n
t_MAYOR_QUE = r'>'
t_MENOR_QUE = r'<'
t_MAYOR_IGUAL = r'>='
t_MENOR_IGUAL = r'<='
t_IGUAL_IGUAL = r'=='
t_DIFERENTE = r'!='

# ðŸ”¹ Ignorar espacios en blanco
t_ignore = " \t\n"

# ðŸ”¹ Ignorar comentarios
def t_ignore_COMENTARIO(t):
    r'//.*'
    pass  # Ignora los comentarios

# ------------------------ Manejo de Errores ------------------------


def t_error(t):
    print(f"âŒ Error lÃ©xico: CarÃ¡cter inesperado '{t.value[0]}'")
    t.lexer.skip(1)

# ------------------------ ConstrucciÃ³n del Lexer ------------------------

lexer = lex.lex()
